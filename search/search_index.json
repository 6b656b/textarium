{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"preprocessing-ref/","title":"Workflow module","text":"<p>Text cleaning and preprocessing functions.</p>"},{"location":"preprocessing-ref/#textarium.preprocessing.remove_charset","title":"<code>remove_charset(text, charset)</code>","text":"<p>Removes provided chars from a string</p> <p>Parameters:</p>    Name Type Description Default     <code>text</code>  <code>str</code>  <p>Any string</p>  required    <code>charset</code>  <code>str</code>  <p>A string of chars which should be removed</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>  <code>str</code>  <p>A string without provided chars</p>     Source code in <code>textarium/preprocessing.py</code> <pre><code>def remove_charset(text: str, charset: string) -&gt; str:\n    \"\"\"Removes provided chars from a string\n\n    Args:\n        text (str): Any string\n        charset (str): A string of chars which should be removed\n\n    Returns:\n        str: A string without provided chars\n    \"\"\"\n    text_wo_charset = text.translate(\n        str.maketrans(charset, \" \" * len(charset))\n    )\n    text_wo_charset = remove_extra_spaces(text_wo_charset)\n\n    return text_wo_charset\n</code></pre>"},{"location":"preprocessing-ref/#textarium.preprocessing.remove_extra_spaces","title":"<code>remove_extra_spaces(text)</code>","text":"<p>Removes extra spaces from a string</p> <p>Parameters:</p>    Name Type Description Default     <code>text</code>  <code>str</code>  <p>Any string</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>  <code>str</code>  <p>A string without extra spaces (maximum 1 space between two words)</p>    <p>Examples:</p> <pre><code>&gt;&gt;&gt; remove_extra_spaces(\"  This line    has extra   spaces   .  \")\n\"This line has extra spaces.\"\n</code></pre>  Source code in <code>textarium/preprocessing.py</code> <pre><code>def remove_extra_spaces(text: str) -&gt; str:\n    \"\"\"Removes extra spaces from a string\n\n    Args:\n        text (str): Any string\n\n    Returns:\n        str: A string without extra spaces (maximum 1 space between two words)\n\n    Examples:\n        &gt;&gt;&gt; remove_extra_spaces(\"  This line    has extra   spaces   .  \")\n        \"This line has extra spaces.\"\n    \"\"\"\n    text_wo_extra_spaces = \" \".join(text.split())\n\n    return text_wo_extra_spaces.strip()\n</code></pre>"},{"location":"preprocessing-ref/#textarium.preprocessing.remove_html","title":"<code>remove_html(text)</code>","text":"<p>Removes HTML-tags and other special symbols from a string</p> <p>Parameters:</p>    Name Type Description Default     <code>text</code>  <code>str</code>  <p>Any string</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>  <code>str</code>  <p>A string without HTML-tags</p>     Source code in <code>textarium/preprocessing.py</code> <pre><code>def remove_html(text: str) -&gt; str:\n    \"\"\"Removes HTML-tags and other special symbols from a string\n\n    Args:\n        text (str): Any string\n\n    Returns:\n        str: A string without HTML-tags\n    \"\"\"\n    re_pattern = re.compile(\"&lt;.*?&gt;+\")\n    text = re_pattern.sub(r\" \", text)\n    text = text.replace(\"&amp;nbsp\", \" \")\n    text = text.replace(\"&amp;lt\", \" \")\n    text = text.replace(\"&amp;gt\", \" \")\n    text_wo_html_tags = remove_extra_spaces(text)\n    return text_wo_html_tags\n</code></pre>"},{"location":"preprocessing-ref/#textarium.preprocessing.remove_tokens","title":"<code>remove_tokens(text, tokenizer, tokens_to_exclude)</code>","text":"<p>Remove any particular words from a string (e.g. stopwords)</p> <p>Parameters:</p>    Name Type Description Default     <code>text</code>  <code>str</code>  <p>Any string</p>  required    <code>tokenizer</code>  <code>Tokenizer</code>  <p>A tokenizer object with a provided <code>.tokenize()</code> method</p>  required    <code>tokens_to_exclude</code>  <code>List</code>  <p>A list of tokens to exclude from a string</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>  <code>str</code>  <p>A string without excluded tokens</p>     Source code in <code>textarium/preprocessing.py</code> <pre><code>def remove_tokens(text: str, tokenizer, tokens_to_exclude: List) -&gt; str:\n    \"\"\"Remove any particular words from a string (e.g. stopwords)\n\n    Args:\n        text (str): Any string\n        tokenizer (Tokenizer): A tokenizer object with a provided `.tokenize()` method\n        tokens_to_exclude (List): A list of tokens to exclude from a string\n\n    Returns:\n        str: A string without excluded tokens\n    \"\"\"\n    tokens = extract_tokens(text, tokenizer)\n    cleaned_tokens = [w for w in tokens if not w in tokens_to_exclude]\n    return \" \".join(cleaned_tokens)\n</code></pre>"},{"location":"preprocessing-ref/#textarium.preprocessing.remove_urls","title":"<code>remove_urls(text)</code>","text":"<p>Removes URLs from a string</p> <p>Parameters:</p>    Name Type Description Default     <code>text</code>  <code>str</code>  <p>Any string</p>  required     <p>Returns:</p>    Name Type Description     <code>str</code>  <code>str</code>  <p>A string without any URLs</p>     Source code in <code>textarium/preprocessing.py</code> <pre><code>def remove_urls(text: str) -&gt; str:\n    \"\"\"Removes URLs from a string\n\n    Args:\n        text (str): Any string\n\n    Returns:\n        str: A string without any URLs\n    \"\"\"\n    url_pattern = re.compile(r\"http\\S+\")\n    text_wo_urls = url_pattern.sub(r\"\", text)\n    text_wo_urls = remove_extra_spaces(text_wo_urls)\n    return text_wo_urls\n</code></pre>"}]}